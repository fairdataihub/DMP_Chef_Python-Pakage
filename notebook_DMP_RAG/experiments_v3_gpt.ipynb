{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e0f6b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 10/08/2025\n"
     ]
    }
   ],
   "source": [
    "print (\"Start 10/08/2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb52b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\ven3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ STEP 1 ready (GPT-4.1 Version)\n",
      "ROOT_DIR   : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\n",
      "DATA_PDFS  : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\NIH_95\n",
      "INDEX_DIR  : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\faiss\n",
      "EXCEL_PATH : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\inputs.xlsx\n",
      "TEMPLATE_MD: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\dmp-template.md\n",
      "OUTPUT_MD  : c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\n",
      "OUTPUT_DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\n",
      "EMBED_MODEL: sentence-transformers/all-MiniLM-L6-v2 | LLM_MODEL: gpt-4.1 | TOP_K: 6\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 1 ‚Äî Imports, Config, and Helpers (GPT-4.1 Version)\n",
    "# ============================================\n",
    "import os, re, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pypandoc  # for Markdown ‚Üí DOCX\n",
    "\n",
    "# --- LangChain Core ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_openai import ChatOpenAI        # <--- GPT replacement\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ---------- Paths (works in notebook or script) ----------\n",
    "try:\n",
    "    ROOT_DIR = Path(__file__).resolve().parents[1]  # running as .py script\n",
    "except NameError:\n",
    "    ROOT_DIR = Path.cwd().parent                    # running in Jupyter Notebook\n",
    "\n",
    "# --- Data folders ---\n",
    "DATA_PDFS   = ROOT_DIR / \"data\" / \"NIH_95\"\n",
    "INDEX_DIR   = ROOT_DIR / \"data\" / \"faiss\"          # renamed for GPT version\n",
    "EXCEL_PATH  = ROOT_DIR / \"data\" / \"inputs\" / \"inputs.xlsx\"\n",
    "TEMPLATE_MD = ROOT_DIR / \"data\" / \"inputs\" / \"dmp-template.md\"\n",
    "\n",
    "# --- Output folders ---\n",
    "OUTPUT_MD   = ROOT_DIR / \"data\" / \"outputs\" / \"markdown\"\n",
    "OUTPUT_DOCX = ROOT_DIR / \"data\" / \"outputs\" / \"docx\"\n",
    "\n",
    "# --- Models / parameters ---\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "LLM_MODEL   = \"gpt-4.1\"                  # <--- GPT model now\n",
    "TOP_K       = 6\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def create_folder(folderpath):\n",
    "    Path(folderpath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_md(folderpath, filename, text):\n",
    "    create_folder(folderpath)\n",
    "    (Path(folderpath) / filename).write_text(text, encoding=\"utf-8\")\n",
    "    print(\"üíæ Saved:\", Path(folderpath) / filename)\n",
    "\n",
    "def md_to_docs(md_filepath, docx_folderpath, docx_filename):\n",
    "    create_folder(docx_folderpath)\n",
    "    pypandoc.convert_file(\n",
    "        str(md_filepath), \"docx\",\n",
    "        outputfile=str(Path(docx_folderpath) / docx_filename)\n",
    "    )\n",
    "    print(\"üìÑ Converted:\", Path(docx_folderpath) / docx_filename)\n",
    "\n",
    "def clean_filename(name: str) -> str:\n",
    "    \"\"\"Remove illegal characters from filenames (Windows-safe).\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", str(name)).strip()\n",
    "\n",
    "# ---------- Ensure required folders exist ----------\n",
    "for p in [DATA_PDFS, INDEX_DIR, OUTPUT_MD, OUTPUT_DOCX]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Initialize GPT LLM ----------\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_MODEL,\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# ---------- Sanity print ----------\n",
    "print(\"‚úÖ STEP 1 ready (GPT-4.1 Version)\")\n",
    "print(f\"ROOT_DIR   : {ROOT_DIR}\")\n",
    "print(f\"DATA_PDFS  : {DATA_PDFS}\")\n",
    "print(f\"INDEX_DIR  : {INDEX_DIR}\")\n",
    "print(f\"EXCEL_PATH : {EXCEL_PATH}\")\n",
    "print(f\"TEMPLATE_MD: {TEMPLATE_MD}\")\n",
    "print(f\"OUTPUT_MD  : {OUTPUT_MD}\")\n",
    "print(f\"OUTPUT_DOCX: {OUTPUT_DOCX}\")\n",
    "print(f\"EMBED_MODEL: {EMBED_MODEL} | LLM_MODEL: {LLM_MODEL} | TOP_K: {TOP_K}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687935b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Loading cached chunks from c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\faiss_index\\chunks_cache.pkl\n",
      "‚úÖ STEP 2 ready ‚Äî 955866 chunks loaded.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# STEP 2 ‚Äî Load PDFs and TXT Files, Split into Text Chunks (Cached) ‚Äî LanceDB Version\n",
    "# =========================================================\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pickle\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Optional: Silence PDFMiner warnings ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pdfminer\")\n",
    "\n",
    "# --- Paths based on your system ---\n",
    "ROOT_DIR = Path(r\"c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\")\n",
    "DATA_PDFS = ROOT_DIR / \"data\" / \"pdfs\"\n",
    "INDEX_DIR = ROOT_DIR / \"data\" / \"faiss_index\"          \n",
    "CHUNK_CACHE_PATH = INDEX_DIR / \"chunks_cache.pkl\"\n",
    "\n",
    "# --- Ensure folders exist ---\n",
    "DATA_PDFS.mkdir(parents=True, exist_ok=True)\n",
    "INDEX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Function: Load PDFs and TXT files\n",
    "# --------------------------------------------------------\n",
    "def load_docs_from_folder(folder: Path):\n",
    "    \"\"\"Load all PDF and TXT files as LangChain Document objects.\"\"\"\n",
    "    if not folder.exists():\n",
    "        raise FileNotFoundError(f\"‚ùå Folder not found: {folder}\")\n",
    "\n",
    "    pdf_files = sorted(folder.glob(\"*.pdf\"))\n",
    "    txt_files = sorted(folder.glob(\"*.txt\"))\n",
    "    all_files = pdf_files + txt_files\n",
    "    if not all_files:\n",
    "        print(f\"‚ö†Ô∏è No PDF or TXT files found in {folder}. Please add some files.\")\n",
    "        return []\n",
    "\n",
    "    docs = []\n",
    "    for fpath in tqdm(all_files, desc=f\"üìÑ Loading files from {folder}\"):\n",
    "        try:\n",
    "            if fpath.suffix.lower() == \".pdf\":\n",
    "                loader = PyPDFLoader(str(fpath))\n",
    "            elif fpath.suffix.lower() == \".txt\":\n",
    "                loader = TextLoader(str(fpath), encoding=\"utf-8\")\n",
    "            else:\n",
    "                print(f\"‚è≠Ô∏è Skipped unsupported file: {fpath.name}\")\n",
    "                continue\n",
    "            docs.extend(loader.load())\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {fpath.name}: {e}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Loaded {len(docs)} pages from {len(all_files)} files in '{folder}'.\")\n",
    "    return docs\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Function: Split documents into chunks\n",
    "# --------------------------------------------------------\n",
    "def split_into_chunks(docs, chunk_size=800, chunk_overlap=120):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    print(f\"üß© Created {len(chunks)} chunks from {len(docs)} document pages.\")\n",
    "    return chunks\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Function: Load or Create Cached Chunks\n",
    "# --------------------------------------------------------\n",
    "def load_or_create_chunks(folder=DATA_PDFS, cache_path=CHUNK_CACHE_PATH):\n",
    "    \"\"\"Load cached chunks if available; otherwise load, split, and cache.\"\"\"\n",
    "    if cache_path.exists():\n",
    "        print(f\"‚ö° Loading cached chunks from {cache_path}\")\n",
    "        with open(cache_path, \"rb\") as f:\n",
    "            chunks = pickle.load(f)\n",
    "    else:\n",
    "        print(\"üïí No cache found ‚Äî processing documents...\")\n",
    "        raw_docs = load_docs_from_folder(folder)\n",
    "        if not raw_docs:\n",
    "            return []  # exit early if folder empty\n",
    "        chunks = split_into_chunks(raw_docs)\n",
    "        cache_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(cache_path, \"wb\") as f:\n",
    "            pickle.dump(chunks, f)\n",
    "        print(f\"üíæ Saved chunks cache ‚Üí {cache_path}\")\n",
    "    return chunks\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Example Run\n",
    "# --------------------------------------------------------\n",
    "chunks = load_or_create_chunks()\n",
    "print(f\"‚úÖ STEP 2 ready ‚Äî {len(chunks)} chunks loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a0f00cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Existing FAISS index found ‚Üí Loading from disk...\n",
      "‚úÖ FAISS index loaded successfully.\n",
      "‚úÖ Retriever ready (top_k=6)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 3 ‚Äî Build or Load FAISS Index (Corrected)\n",
    "# ============================================\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Initialize embedding model ---\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
    "\n",
    "\n",
    "def build_or_load_faiss_index(index_dir=INDEX_DIR, chunks=None):\n",
    "    \"\"\"\n",
    "    Loads FAISS index from cache if it exists.\n",
    "    Otherwise, builds a new index from chunks and saves it.\n",
    "    \"\"\"\n",
    "\n",
    "    # Correct FAISS file paths\n",
    "    faiss_path = index_dir / \"index.faiss\"\n",
    "    pkl_path   = index_dir / \"index.pkl\"\n",
    "\n",
    "    # --- 1) LOAD EXISTING INDEX ---\n",
    "    if faiss_path.exists() and pkl_path.exists():\n",
    "        print(\"üì¶ Existing FAISS index found ‚Üí Loading from disk...\")\n",
    "\n",
    "        vectorstore = FAISS.load_local(\n",
    "            str(index_dir),\n",
    "            embeddings,\n",
    "            allow_dangerous_deserialization=True   # required for LC v0.1+\n",
    "        )\n",
    "\n",
    "        print(\"‚úÖ FAISS index loaded successfully.\")\n",
    "        return vectorstore\n",
    "\n",
    "    # --- 2) BUILD NEW INDEX ---\n",
    "    if chunks is None or len(chunks) == 0:\n",
    "        raise RuntimeError(\"‚ùå No chunks provided ‚Äî run Step 2 before building FAISS.\")\n",
    "\n",
    "    print(\"üß± No FAISS index found ‚Üí Building a new one...\")\n",
    "    index_dir.mkdir(parents=True, exist_ok=True)\n",
    "    start_time = time.time()\n",
    "\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        tqdm(chunks, desc=\"üî¢ Embedding and indexing chunks\"),\n",
    "        embeddings\n",
    "    )\n",
    "\n",
    "    # Save index to disk\n",
    "    vectorstore.save_local(str(index_dir))\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"üíæ Saved new FAISS index to {index_dir}\")\n",
    "    print(f\"‚è±Ô∏è Build completed in {duration:.1f} seconds ({duration/60:.2f} min)\")\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# EXECUTE STEP 3\n",
    "# ---------------------------------------------------------\n",
    "vectorstore = build_or_load_faiss_index(INDEX_DIR, chunks)\n",
    "retriever   = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
    "\n",
    "print(f\"‚úÖ Retriever ready (top_k={TOP_K})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d9b2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Excel loaded successfully: 26 rows\n",
      "‚úÖ DMP Markdown template loaded.\n",
      "üîó RAG chain initialized with GPT model: gpt-4.1\n",
      "‚úÖ RAG chain ready for GPT generation.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üß© STEP 4 ‚Äî Load Excel, Template, and Build RAG Chain (GPT Version)\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI   # <-- GPT replacement\n",
    "\n",
    "# --- Load Excel file ---\n",
    "if not EXCEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Excel file not found: {EXCEL_PATH}\")\n",
    "\n",
    "df = pd.read_excel(EXCEL_PATH)\n",
    "print(f\"‚úÖ Excel loaded successfully: {len(df)} rows\")\n",
    "\n",
    "# --- Load Markdown Template ---\n",
    "if not TEMPLATE_MD.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Template file not found: {TEMPLATE_MD}\")\n",
    "\n",
    "dmp_template_text = TEMPLATE_MD.read_text(encoding=\"utf-8\")\n",
    "print(\"‚úÖ DMP Markdown template loaded.\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# üî® Build RAG chain for GPT\n",
    "# ---------------------------------------------------------\n",
    "def build_rag_chain(retriever, llm_model=LLM_MODEL):\n",
    "    \"\"\"\n",
    "    Build a GPT-powered RAG pipeline that retrieves context\n",
    "    and generates a context-grounded NIH DMP section.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize GPT model\n",
    "    llm = ChatOpenAI(\n",
    "        model=llm_model,\n",
    "        temperature=0.2,\n",
    "        max_tokens=1500\n",
    "    )\n",
    "\n",
    "    # GPT prompt template\n",
    "    prompt_template = \"\"\"\n",
    "You are an expert biomedical data steward and NIH DMSP writer.\n",
    "Using the retrieved context and the question, generate a clear,\n",
    "NIH-compliant Data Management and Sharing Plan section.\n",
    "\n",
    "==============================\n",
    "üìò Retrieved Context:\n",
    "{context}\n",
    "==============================\n",
    "\n",
    "‚ùì Question:\n",
    "{question}\n",
    "==============================\n",
    "\n",
    "Guidelines:\n",
    "- Use ONLY information from the context.\n",
    "- Do NOT hallucinate missing details.\n",
    "- Write according to NIH DMSP style and structure.\n",
    "- Make the writing clean, professional, and cohesive.\n",
    "\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    # --- Format retrieved docs for GPT ---\n",
    "    def format_docs(docs):\n",
    "        if not docs:\n",
    "            return \"No relevant context found.\"\n",
    "        formatted = []\n",
    "        for d in docs:\n",
    "            page = d.metadata.get(\"page\", \"\")\n",
    "            title = d.metadata.get(\"source\", \"Unknown Source\")\n",
    "            formatted.append(\n",
    "                f\"Source: {title} | Page {page}\\n{d.page_content.strip()}\"\n",
    "            )\n",
    "        return \"\\n\\n\".join(formatted)\n",
    "\n",
    "    # --- Build final chain ---\n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": retriever | format_docs,\n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | parser\n",
    "    )\n",
    "\n",
    "    print(f\"üîó RAG chain initialized with GPT model: {llm_model}\")\n",
    "    return rag_chain\n",
    "\n",
    "\n",
    "# --- Initialize the RAG chain ---\n",
    "rag_chain = build_rag_chain(retriever)\n",
    "print(\"‚úÖ RAG chain ready for GPT generation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dd1758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded input Excel ‚Äî 26 rows\n",
      "‚úÖ Loaded NIH DMP Markdown template from: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\dmp-template.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß© Generating DMP for: Clinical and MRI data from human research participants\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nahid\\AppData\\Local\\Temp\\ipykernel_23600\\450686252.py:87: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query_intro)\n",
      "üß† Generating NIH DMPs:   4%|‚ñç         | 1/26 [00:32<13:25, 32.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Clinical and MRI data from human research participants.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Clinical and MRI data from human research participants.docx\n",
      "\n",
      "üß© Generating DMP for: Genomic data from human research participants\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:   8%|‚ñä         | 2/26 [00:54<10:30, 26.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Genomic data from human research participants.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Genomic data from human research participants.docx\n",
      "\n",
      "üß© Generating DMP for: Genomic data from a non-human source\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  12%|‚ñà‚ñè        | 3/26 [01:13<08:49, 23.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Genomic data from a non-human source.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Genomic data from a non-human source.docx\n",
      "\n",
      "üß© Generating DMP for: Secondary data analysis\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  15%|‚ñà‚ñå        | 4/26 [01:33<07:59, 21.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Secondary data analysis.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Secondary data analysis.docx\n",
      "\n",
      "üß© Generating DMP for: Human clinical and genomics data\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  19%|‚ñà‚ñâ        | 5/26 [02:04<08:49, 25.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Human clinical and genomics data.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Human clinical and genomics data.docx\n",
      "\n",
      "üß© Generating DMP for: Gene expression analysis data from non-human model organism (zebrafish)\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  23%|‚ñà‚ñà‚ñé       | 6/26 [02:27<08:08, 24.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Gene expression analysis data from non-human model organism (zebrafish).md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Gene expression analysis data from non-human model organism (zebrafish).docx\n",
      "\n",
      "üß© Generating DMP for: Human survey data\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  27%|‚ñà‚ñà‚ñã       | 7/26 [02:47<07:16, 23.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Human survey data.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Human survey data.docx\n",
      "\n",
      "üß© Generating DMP for: Clinical Data from Human Research Participants\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  31%|‚ñà‚ñà‚ñà       | 8/26 [03:05<06:22, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Clinical Data from Human Research Participants.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Clinical Data from Human Research Participants.docx\n",
      "\n",
      "üß© Generating DMP for: Human genomic data\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [03:27<06:05, 21.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Human genomic data.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Human genomic data.docx\n",
      "\n",
      "üß© Generating DMP for: Technology development\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [03:41<05:08, 19.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Technology development.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Technology development.docx\n",
      "\n",
      "üß© Generating DMP for: Basic Research from a Non-Human Source Example\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [04:00<04:45, 19.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Basic Research from a Non-Human Source Example.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Basic Research from a Non-Human Source Example.docx\n",
      "\n",
      "üß© Generating DMP for: Secondary Data Analysis Example\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [04:23<04:47, 20.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Secondary Data Analysis Example.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Secondary Data Analysis Example.docx\n",
      "\n",
      "üß© Generating DMP for: Survey and Interview Example\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [04:45<04:30, 20.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Survey and Interview Example.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Survey and Interview Example.docx\n",
      "\n",
      "üß© Generating DMP for: Human Clinical Trial Data\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [05:13<04:34, 22.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Human Clinical Trial Data.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Human Clinical Trial Data.docx\n",
      "\n",
      "üß© Generating DMP for: Clinical data from human research participants-NIA\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [05:31<03:57, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Clinical data from human research participants-NIA.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Clinical data from human research participants-NIA.docx\n",
      "\n",
      "üß© Generating DMP for: Survey, interview, and biological data (tiered access)\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [06:14<04:38, 27.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Survey, interview, and biological data (tiered access).md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Survey, interview, and biological data (tiered access).docx\n",
      "\n",
      "üß© Generating DMP for: Non-human data (primates)\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [06:31<03:41, 24.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Non-human data (primates).md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Non-human data (primates).docx\n",
      "\n",
      "üß© Generating DMP for: Secondary data analysis-NIA\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [06:57<03:22, 25.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Secondary data analysis-NIA.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Secondary data analysis-NIA.docx\n",
      "\n",
      "üß© Generating DMP for: Survey and interview data-NIA\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [07:13<02:36, 22.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Survey and interview data-NIA.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Survey and interview data-NIA.docx\n",
      "\n",
      "üß© Generating DMP for: Human clinical and genomic data-NIA\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [07:35<02:12, 22.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Human clinical and genomic data-NIA.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Human clinical and genomic data-NIA.docx\n",
      "\n",
      "üß© Generating DMP for: Non-human data (rodents)-NIA\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [07:48<01:37, 19.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Non-human data (rodents)-NIA.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Non-human data (rodents)-NIA.docx\n",
      "\n",
      "üß© Generating DMP for: Clinical data (human biospecimens)\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [08:02<01:11, 17.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Clinical data (human biospecimens).md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Clinical data (human biospecimens).docx\n",
      "\n",
      "üß© Generating DMP for: Drug discovery including intellectual property\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [08:24<00:57, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Drug discovery including intellectual property.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Drug discovery including intellectual property.docx\n",
      "\n",
      "üß© Generating DMP for: HeLa Cell Whole Genome Sequence (DNA or RNA)\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [08:48<00:41, 20.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\HeLa Cell Whole Genome Sequence (DNA or RNA).md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\HeLa Cell Whole Genome Sequence (DNA or RNA).docx\n",
      "\n",
      "üß© Generating DMP for: Secondary Data Analysis on Data from Human Subjects-NIA\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [09:18<00:23, 23.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Secondary Data Analysis on Data from Human Subjects-NIA.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Secondary Data Analysis on Data from Human Subjects-NIA.docx\n",
      "\n",
      "üß© Generating DMP for: Analysis of social media posts\n",
      "üîé Retrieved 6 context chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß† Generating NIH DMPs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [09:44<00:00, 22.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved Markdown: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\\Analysis of social media posts.md\n",
      "üìÑ Converted to DOCX: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\docx\\Analysis of social media posts.docx\n",
      "\n",
      "‚úÖ All NIH DMPs generated successfully ‚Äî titles preserved exactly as in Excel!\n",
      "üìä CSV log saved to: c:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\rag_generated_dmp_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üß© STEP 5 ‚Äî RAG-Based DMP Generation Using Titles (GPT Version)\n",
    "# ============================================\n",
    "import re\n",
    "import pandas as pd\n",
    "import pypandoc\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- Paths ----------\n",
    "EXCEL_PATH  = ROOT_DIR / \"data\" / \"inputs\" / \"inputs.xlsx\"\n",
    "OUTPUT_LOG  = ROOT_DIR / \"data\" / \"outputs\" / \"rag_generated_dmp_log.csv\"\n",
    "\n",
    "OUTPUT_MD.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DOCX.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Load Excel ----------\n",
    "df = pd.read_excel(EXCEL_PATH)\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "print(f\"‚úÖ Loaded input Excel ‚Äî {len(df)} rows\")\n",
    "\n",
    "# ---------- Verify template ----------\n",
    "if not TEMPLATE_MD.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Template not found: {TEMPLATE_MD}\")\n",
    "\n",
    "dmp_template_text = TEMPLATE_MD.read_text(encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Loaded NIH DMP Markdown template from: {TEMPLATE_MD}\")\n",
    "\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def sanitize_filename(name: str) -> str:\n",
    "    \"\"\"Windows-safe filename formatting.\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", name.strip())\n",
    "\n",
    "def create_folder(folderpath: Path):\n",
    "    folderpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_md(folderpath: Path, filename: str, text: str):\n",
    "    create_folder(folderpath)\n",
    "    filepath = folderpath / filename\n",
    "    filepath.write_text(text, encoding=\"utf-8\")\n",
    "    print(f\"üíæ Saved Markdown: {filepath}\")\n",
    "\n",
    "def md_to_docx(md_filepath: Path, docx_folder: Path, docx_filename: str):\n",
    "    create_folder(docx_folder)\n",
    "    docx_path = docx_folder / docx_filename\n",
    "    pypandoc.convert_file(str(md_filepath), \"docx\", outputfile=str(docx_path))\n",
    "    print(f\"üìÑ Converted to DOCX: {docx_path}\")\n",
    "\n",
    "\n",
    "# ---------- MAIN GENERATION ----------\n",
    "records = []\n",
    "TOP_K = 6\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"üß† Generating NIH DMPs\"):\n",
    "    \n",
    "    title = str(row[\"title\"]).strip()\n",
    "    safe_title = sanitize_filename(title)\n",
    "    print(f\"\\nüß© Generating DMP for: {title}\")\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 1Ô∏è‚É£ Build Query Text from Excel Elements\n",
    "    # -------------------------------------------------------\n",
    "    element_texts = []\n",
    "    for col in df.columns:\n",
    "        if col.startswith(\"element\"):\n",
    "            val = str(row[col]).strip()\n",
    "            if val:\n",
    "                element_texts.append(f\"{col.upper()}: {val}\")\n",
    "\n",
    "    query_data = \"\\n\".join(element_texts)\n",
    "\n",
    "    query_intro = (\n",
    "        f\"You are an expert biomedical data steward and NIH grant writer.\\n\"\n",
    "        f\"Generate a complete Data Management and Sharing Plan (DMSP) for the project titled:\\n\"\n",
    "        f\"'{title}'.\\n\"\n",
    "        f\"Use proposal background below to guide the generation.\\n\\n\"\n",
    "        f\"Proposal Information:\\n{query_data}\\n\"\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 2Ô∏è‚É£ Retrieve Context from FAISS\n",
    "    # -------------------------------------------------------\n",
    "    try:\n",
    "        retrieved_docs = retriever.get_relevant_documents(query_intro)\n",
    "        retrieved_docs = retrieved_docs[:TOP_K]\n",
    "        context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "        print(f\"üîé Retrieved {len(retrieved_docs)} context chunks.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Retrieval failed for {title}: {e}\")\n",
    "        context_text = \"\"\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 3Ô∏è‚É£ Build Final Prompt for GPT RAG Chain\n",
    "    # -------------------------------------------------------\n",
    "    full_prompt = f\"\"\"\n",
    "You are an expert biomedical data steward and NIH DMSP writer.\n",
    "\n",
    "Your task:\n",
    "Generate a complete NIH-compliant Data Management and Sharing Plan (DMSP) using:\n",
    "1. Retrieved NIH context\n",
    "2. Proposal background provided\n",
    "3. The NIH DMSP template (DO NOT modify headings)\n",
    "\n",
    "============================\n",
    "üìò Retrieved NIH Context:\n",
    "{context_text}\n",
    "============================\n",
    "\n",
    "üìÑ Proposal Information:\n",
    "{query_intro}\n",
    "\n",
    "============================\n",
    "üìë NIH DMSP Markdown Template:\n",
    "{dmp_template_text}\n",
    "============================\n",
    "\n",
    "Write the DMSP clearly, accurately, and professionally.\n",
    "Do NOT hallucinate information not supported by the context.\n",
    "\"\"\"\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 4Ô∏è‚É£ Generate using GPT RAG chain (rag_chain.invoke)\n",
    "    # -------------------------------------------------------\n",
    "    try:\n",
    "        response = rag_chain.invoke(full_prompt)\n",
    "\n",
    "        # 5Ô∏è‚É£ Save output with original title\n",
    "        md_filename = f\"{safe_title}.md\"\n",
    "        docx_filename = f\"{safe_title}.docx\"\n",
    "        md_path = OUTPUT_MD / md_filename\n",
    "\n",
    "        save_md(OUTPUT_MD, md_filename, response)\n",
    "        md_to_docx(md_path, OUTPUT_DOCX, docx_filename)\n",
    "\n",
    "        records.append({\n",
    "            \"Title\": title,\n",
    "            \"Query\": query_intro,\n",
    "            \"Retrieved_Context\": context_text[:1000],\n",
    "            \"Generated_DMP_Preview\": response[:1000],\n",
    "            \"Error\": \"\"\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating DMP for {title}: {e}\")\n",
    "        records.append({\n",
    "            \"Title\": title,\n",
    "            \"Query\": query_intro,\n",
    "            \"Retrieved_Context\": context_text[:1000],\n",
    "            \"Generated_DMP_Preview\": \"\",\n",
    "            \"Error\": str(e)\n",
    "        })\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6Ô∏è‚É£ Save Log File\n",
    "# -------------------------------------------------------\n",
    "pd.DataFrame(records).to_csv(OUTPUT_LOG, index=False, encoding=\"utf-8\")\n",
    "print(\"\\n‚úÖ All NIH DMPs generated successfully ‚Äî titles preserved exactly as in Excel!\")\n",
    "print(f\"üìä CSV log saved to: {OUTPUT_LOG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74e73797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìó Gold PDF folder: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\gold_dmps\n",
      "üìò Generated Markdown folder: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\n",
      "üöÄ Loading models...\n",
      "‚úÖ Models ready.\n",
      "üìä Found 26 generated DMPs and 26 gold PDFs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:   4%|‚ñç         | 1/26 [00:00<00:08,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Analysis of social media posts.md ‚Üî 26-Analysis of social media posts-NCI.pdf (score=0.90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:   8%|‚ñä         | 2/26 [00:00<00:07,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Basic Research from a Non-Human Source Example.md ‚Üî 11-Basic Research from a Non-Human Source Example-NIDDK.pdf (score=0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  12%|‚ñà‚ñè        | 3/26 [00:01<00:08,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Clinical and MRI data from human research participants.md ‚Üî 1-Clinical andor MRI data from human research participants-NIMH.pdf (score=0.92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  15%|‚ñà‚ñå        | 4/26 [00:01<00:07,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Clinical data (human biospecimens).md ‚Üî 22-Clinical data (human biospecimens)-NIA.pdf (score=0.90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  19%|‚ñà‚ñâ        | 5/26 [00:01<00:06,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Clinical data from human research participants-NIA.md ‚Üî 15-Clinical data from human research participants-NIA.pdf (score=0.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:01<00:05,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Clinical Data from Human Research Participants.md ‚Üî 15-Clinical data from human research participants-NIA.pdf (score=0.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:02<00:05,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Drug discovery including intellectual property.md ‚Üî 23-Drug discovery including intellectual property-NIA.pdf (score=0.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:02<00:05,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Gene expression analysis data from non-human model organism (zebrafish).md ‚Üî 8-Gene expression analysis data from non-human model organism (zebrafish)-NICHD.pdf (score=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:02<00:05,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Genomic data from a non-human source.md ‚Üî 3-Genomic data from a non-human source-NIMH.pdf (score=0.91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:03<00:05,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Genomic data from human research participants.md ‚Üî 2-Genomic data from human research participants-NIMH.pdf (score=0.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:03<00:04,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched HeLa Cell Whole Genome Sequence (DNA or RNA).md ‚Üî 24-HeLa Cell Whole Genome Sequence (DNA or RNA)-OD, NHGRI.pdf (score=0.88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:03<00:04,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Human clinical and genomic data-NIA.md ‚Üî 20-Human clinical and genomic data-NIA.pdf (score=0.96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:04<00:04,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Human clinical and genomics data.md ‚Üî 7-Human clinical and genomics data-NICHD.pdf (score=0.89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:04<00:04,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Human Clinical Trial Data.md ‚Üî 14-Human Clinical Trial Data-NICHD.pdf (score=0.85)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:05<00:04,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Human genomic data.md ‚Üî 5-Human genomic data-NHGRI.pdf (score=0.82)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:05<00:04,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Human survey data.md ‚Üî 9-Human survey data-NICHD.pdf (score=0.81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:05<00:03,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Non-human data (primates).md ‚Üî 17-Non-human data (primates)-NIA.pdf (score=0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:06<00:02,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Non-human data (rodents)-NIA.md ‚Üî 21-Non-human data (rodents)-NIA.pdf (score=0.95)\n",
      "‚úÖ Matched Secondary Data Analysis Example.md ‚Üî 12-Secondary Data Analysis Example-NIDDK.pdf (score=0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:06<00:01,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Secondary Data Analysis on Data from Human Subjects-NIA.md ‚Üî 25-Secondary Data Analysis on Data from Human Subjects-NIA.pdf (score=0.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:06<00:01,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Secondary data analysis-NIA.md ‚Üî 18-Secondary data analysis-NIA.pdf (score=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:07<00:01,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Secondary data analysis.md ‚Üî 18-Secondary data analysis-NIA.pdf (score=0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:07<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Survey and interview data-NIA.md ‚Üî 19-Survey and interview data-NIA.pdf (score=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:07<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Survey and Interview Example.md ‚Üî 13-Survey and Interview Example-NHGRI.pdf (score=0.86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:08<00:00,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Survey, interview, and biological data (tiered access).md ‚Üî 16-Survey, interview, and biological data (tiered access)-NIA.pdf (score=0.93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Matching & Comparing DMPs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:08<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Matched Technology development.md ‚Üî 6-Technology development-NHGRI.pdf (score=0.85)\n",
      "\n",
      "‚úÖ Markdown‚ÄìPDF (fuzzy) similarity results saved to: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\evaluation_results\\full_dmp_pdf_comparison_fuzzy.csv\n",
      "üßæ Total matched DMP pairs: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üß© STEP 6 ‚Äî Full DMP Comparison: Markdown (Generated) vs PDF (Gold, Fuzzy Matching)\n",
    "# ============================================\n",
    "import os, re\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# üóÇÔ∏è Define ROOT_DIR manually to your project folder\n",
    "# --------------------------------------------------------\n",
    "ROOT_DIR = Path(r\"C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\")  # ‚úÖ change if needed\n",
    "\n",
    "# --- Paths ---\n",
    "GOLD_DIR      = ROOT_DIR / \"data\" /\"inputs\"/ \"gold_dmps\"      # PDF gold-standard DMPs\n",
    "GENERATED_DIR = ROOT_DIR / \"data\" / \"outputs\" / \"markdown\"      # Generated DMPs\n",
    "EVAL_DIR      = ROOT_DIR / \"data\" / \"outputs\" / \"evaluation_results\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìó Gold PDF folder: {GOLD_DIR}\")\n",
    "print(f\"üìò Generated Markdown folder: {GENERATED_DIR}\")\n",
    "\n",
    "# --- Models ---\n",
    "print(\"üöÄ Loading models...\")\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "print(\"‚úÖ Models ready.\")\n",
    "\n",
    "# --- Helper functions ---\n",
    "def normalize_name(name: str) -> str:\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[^a-z0-9\\s]\", \" \", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Remove markdown or formatting artifacts.\"\"\"\n",
    "    text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL)\n",
    "    text = re.sub(r\"#+\\s*\", \"\", text)\n",
    "    text = re.sub(r\"\\*\\*|\\*\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    \"\"\"Extract readable text from PDF using PyMuPDF.\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text(\"text\") + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading {pdf_path.name}: {e}\")\n",
    "    return clean_text(text)\n",
    "\n",
    "def chunk_text(text, size=300):\n",
    "    \"\"\"Split long text into 300-word chunks.\"\"\"\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+size]) for i in range(0, len(words), size)]\n",
    "\n",
    "def compare_chunked(gold_text, gen_text, model):\n",
    "    \"\"\"Chunked SBERT + ROUGE similarity between two long texts.\"\"\"\n",
    "    gold_chunks = chunk_text(gold_text)\n",
    "    gen_chunks = chunk_text(gen_text)\n",
    "\n",
    "    sbert_scores, rouge_scores = [], []\n",
    "    for g in gold_chunks:\n",
    "        emb_g = model.encode(g, convert_to_tensor=True)\n",
    "        chunk_sims = []\n",
    "        for gen in gen_chunks:\n",
    "            emb_gen = model.encode(gen, convert_to_tensor=True)\n",
    "            chunk_sims.append(util.cos_sim(emb_g, emb_gen).item())\n",
    "        sbert_scores.append(max(chunk_sims))  # best match per gold chunk\n",
    "\n",
    "        rouge_chunk_scores = [rouge.score(g, gen)[\"rougeL\"].recall for gen in gen_chunks]\n",
    "        rouge_scores.append(max(rouge_chunk_scores))\n",
    "\n",
    "    return np.mean(sbert_scores), np.mean(rouge_scores)\n",
    "\n",
    "def best_fuzzy_match(target, gold_names, threshold=0.6):\n",
    "    \"\"\"Find best matching name among gold files using fuzzy ratio.\"\"\"\n",
    "    best_match, best_score = None, 0\n",
    "    for g in gold_names:\n",
    "        score = SequenceMatcher(None, target, g).ratio()\n",
    "        if score > best_score:\n",
    "            best_match, best_score = g, score\n",
    "    return (best_match, best_score) if best_score >= threshold else (None, best_score)\n",
    "\n",
    "# --- Collect gold PDFs and generated MDs ---\n",
    "gold_files = {normalize_name(f.stem): f for f in GOLD_DIR.glob(\"*.pdf\")}\n",
    "gen_files  = {normalize_name(f.stem): f for f in GENERATED_DIR.glob(\"*.md\")}\n",
    "print(f\"üìä Found {len(gen_files)} generated DMPs and {len(gold_files)} gold PDFs.\")\n",
    "\n",
    "# --- Compare all matching files ---\n",
    "results = []\n",
    "for name, gen_path in tqdm(gen_files.items(), desc=\"üîé Matching & Comparing DMPs\"):\n",
    "    best_match, score = best_fuzzy_match(name, list(gold_files.keys()))\n",
    "    if not best_match:\n",
    "        print(f\"‚ö†Ô∏è No gold match for: {gen_path.name}\")\n",
    "        continue\n",
    "\n",
    "    gold_path = gold_files[best_match]\n",
    "    gold_text = extract_text_from_pdf(gold_path)\n",
    "    gen_text  = clean_text(gen_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    if not gold_text.strip() or not gen_text.strip():\n",
    "        print(f\"‚ö†Ô∏è Skipping empty file: {name}\")\n",
    "        continue\n",
    "\n",
    "    sbert_sim, rouge_l = compare_chunked(gold_text, gen_text, sbert)\n",
    "    results.append({\n",
    "        \"Generated_File\": gen_path.name,\n",
    "        \"Matched_Gold_PDF\": gold_path.name,\n",
    "        \"Match_Score\": round(score, 3),\n",
    "        \"SBERT_Similarity\": round(sbert_sim, 4),\n",
    "        \"ROUGE_L_Recall\": round(rouge_l, 4),\n",
    "    })\n",
    "    print(f\"‚úÖ Matched {gen_path.name} ‚Üî {gold_path.name} (score={score:.2f})\")\n",
    "\n",
    "# --- Save results ---\n",
    "df_results = pd.DataFrame(results)\n",
    "out_path = EVAL_DIR / \"full_dmp_pdf_comparison_fuzzy.csv\"\n",
    "df_results.to_csv(out_path, index=False)\n",
    "print(f\"\\n‚úÖ Markdown‚ÄìPDF (fuzzy) similarity results saved to: {out_path}\")\n",
    "print(f\"üßæ Total matched DMP pairs: {len(df_results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b457323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ ROOT_DIR set to: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\n",
      "üìó Gold Excel: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\inputs\\inputs.xlsx\n",
      "üìò Generated MD folder: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\markdown\n",
      "‚úÖ Loaded 26 gold projects.\n",
      "üöÄ Loading evaluation models...\n",
      "‚úÖ Models ready.\n",
      "üîç Found 26 generated Markdown files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üìä Comparing element-level: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:26<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Element-level similarity saved to: C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\evaluation_results\\element_similarity_exact_titles.csv\n",
      "üßæ Total element‚Äìsection best matches: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üß© STEP 7 ‚Äî Element-Level Comparison with NIH Gold Standard (Exact Title Match)\n",
    "# ============================================\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# --- Paths ---\n",
    "# --- Define ROOT_DIR dynamically (project root) ---\n",
    "from pathlib import Path\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# üóÇÔ∏è Define ROOT_DIR manually to your project folder\n",
    "# --------------------------------------------------------\n",
    "ROOT_DIR = Path(r\"C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\")  # ‚úÖ change if needed\n",
    "\n",
    "print(f\"üìÇ ROOT_DIR set to: {ROOT_DIR}\")\n",
    "GOLD_PATH      = ROOT_DIR / \"data\" / \"inputs\" / \"inputs.xlsx\"\n",
    "GENERATED_DIR  = ROOT_DIR / \"data\" / \"outputs\" / \"markdown\"\n",
    "EVAL_DIR       = ROOT_DIR / \"data\" / \"outputs\" / \"evaluation_results\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìó Gold Excel: {GOLD_PATH}\")\n",
    "print(f\"üìò Generated MD folder: {GENERATED_DIR}\")\n",
    "\n",
    "# --- Load gold reference (Excel) ---\n",
    "df_gold = pd.read_excel(GOLD_PATH)\n",
    "df_gold.columns = df_gold.columns.str.strip().str.lower()\n",
    "df_gold = df_gold.fillna(\"\").astype(str)\n",
    "\n",
    "def normalize_title(name: str) -> str:\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[^a-z0-9\\s]\", \" \", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "df_gold[\"title_norm\"] = df_gold[\"title\"].apply(normalize_title)\n",
    "\n",
    "gold_elements = [\n",
    "    \"element_1a\",\"element_1b\",\"element_1c\",\n",
    "    \"element_2\",\"element_3\",\n",
    "    \"element_4a\",\"element_4b\",\"element_4c\",\n",
    "    \"element_5a\",\"element_5b\",\"element_5c\",\n",
    "    \"element_6\"\n",
    "]\n",
    "print(f\"‚úÖ Loaded {len(df_gold)} gold projects.\")\n",
    "\n",
    "# --- Models ---\n",
    "print(\"üöÄ Loading evaluation models...\")\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "print(\"‚úÖ Models ready.\")\n",
    "\n",
    "# --- Markdown parsing helpers ---\n",
    "def is_title(line: str) -> bool:\n",
    "    s = line.strip()\n",
    "    # Accept markdown headers (#, ##, ...) OR numbered bold section titles like \"1. **Data Types**\"\n",
    "    return s.startswith(\"#\") or bool(re.match(r\"^\\s*\\d*\\.?\\s*\\*\\*.*\\*\\*\\s*$\", s))\n",
    "\n",
    "def extract_sections(md_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract {Section Title, Generated Content} pairs from a Markdown file.\n",
    "    Also strips any <think>...</think> blocks if present.\n",
    "    \"\"\"\n",
    "    text = md_path.read_text(encoding=\"utf-8\")\n",
    "    text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL)\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    entries, current_title, buf = [], None, []\n",
    "\n",
    "    for ln in lines:\n",
    "        if is_title(ln):\n",
    "            if current_title and any(x.strip() for x in buf):\n",
    "                entries.append({\n",
    "                    \"Section Title\": current_title.strip(),\n",
    "                    \"Generated Content\": \"\\n\".join(buf).strip()\n",
    "                })\n",
    "            current_title, buf = ln, []\n",
    "        else:\n",
    "            buf.append(ln)\n",
    "\n",
    "    if current_title and any(x.strip() for x in buf):\n",
    "        entries.append({\n",
    "            \"Section Title\": current_title.strip(),\n",
    "            \"Generated Content\": \"\\n\".join(buf).strip()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(entries)\n",
    "\n",
    "# --- Compare (exact title match) ---\n",
    "results = []\n",
    "md_files = sorted(GENERATED_DIR.glob(\"*.md\"))\n",
    "print(f\"üîç Found {len(md_files)} generated Markdown files.\")\n",
    "\n",
    "for md_file in tqdm(md_files, desc=\"üìä Comparing element-level\"):\n",
    "    # Your MD files are saved with the SAME title (sanitized) ‚Äî reverse-sanitize to match Excel\n",
    "    # We‚Äôll normalize both sides and do exact equality on normalized strings\n",
    "    gen_title_raw = md_file.stem  # e.g., \"National Institute of Mental Health (NIMH)\"\n",
    "    gen_title_norm = normalize_title(gen_title_raw)\n",
    "\n",
    "    gold_row = df_gold[df_gold[\"title_norm\"] == gen_title_norm]\n",
    "    if gold_row.empty:\n",
    "        print(f\"‚ö†Ô∏è No gold match for file: {md_file.name}\")\n",
    "        continue\n",
    "\n",
    "    gold_row = gold_row.iloc[0]\n",
    "    gold_title = gold_row[\"title\"]\n",
    "\n",
    "    # Gather gold element texts\n",
    "    gold_texts = {e: gold_row.get(e, \"\").strip() for e in gold_elements if gold_row.get(e, \"\").strip()}\n",
    "    if not gold_texts:\n",
    "        print(f\"‚ö†Ô∏è Empty gold elements for: {gold_title}\")\n",
    "        continue\n",
    "\n",
    "    # Extract sections from generated MD\n",
    "    gen_df = extract_sections(md_file)\n",
    "    if gen_df.empty:\n",
    "        print(f\"‚ö†Ô∏è No sections extracted from: {md_file.name}\")\n",
    "        continue\n",
    "\n",
    "    # For each gold element, compare to ALL generated sections; keep best match\n",
    "    for element, gold_text in gold_texts.items():\n",
    "        best = None\n",
    "        for _, sec in gen_df.iterrows():\n",
    "            gen_text = str(sec[\"Generated Content\"]).strip()\n",
    "            if not gen_text:\n",
    "                continue\n",
    "\n",
    "            emb_gold = sbert.encode(gold_text, convert_to_tensor=True)\n",
    "            emb_gen  = sbert.encode(gen_text,  convert_to_tensor=True)\n",
    "            sbert_sim = util.cos_sim(emb_gold, emb_gen).item()\n",
    "            rouge_l   = rouge.score(gold_text, gen_text)[\"rougeL\"].recall\n",
    "\n",
    "            cand = {\n",
    "                \"Gold Project\": gold_title,\n",
    "                \"Gold Element\": element,\n",
    "                \"Generated File\": md_file.name,\n",
    "                \"Generated Section Title\": sec[\"Section Title\"],\n",
    "                \"SBERT_Similarity\": round(sbert_sim, 4),\n",
    "                \"ROUGE_L_Recall\": round(rouge_l, 4),\n",
    "            }\n",
    "            if (best is None) or (sbert_sim > best[\"SBERT_Similarity\"]):\n",
    "                best = cand\n",
    "\n",
    "        if best:\n",
    "            results.append(best)\n",
    "\n",
    "# --- Save ---\n",
    "df_results = pd.DataFrame(results)\n",
    "out_path = EVAL_DIR / \"element_similarity_exact_titles.csv\"\n",
    "df_results.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Element-level similarity saved to: {out_path}\")\n",
    "print(f\"üßæ Total element‚Äìsection best matches: {len(df_results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54a11b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded full-document (26 rows)\n",
      "‚úÖ Loaded element-level (312 rows)\n",
      "\n",
      "üìä Full-document summary table (Mean only, by Generated_File):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated_File</th>\n",
       "      <th>SBERT</th>\n",
       "      <th>ROUGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analysis of social media posts.md</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic Research from a Non-Human Source Example.md</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clinical Data from Human Research Participants.md</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical and MRI data from human research part...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical data (human biospecimens).md</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clinical data from human research participants...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Drug discovery including intellectual property.md</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gene expression analysis data from non-human m...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Genomic data from a non-human source.md</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Genomic data from human research participants.md</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HeLa Cell Whole Genome Sequence (DNA or RNA).md</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Human Clinical Trial Data.md</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Human clinical and genomic data-NIA.md</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Human clinical and genomics data.md</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Human genomic data.md</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Human survey data.md</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Non-human data (primates).md</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Non-human data (rodents)-NIA.md</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Secondary Data Analysis Example.md</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Secondary Data Analysis on Data from Human Sub...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Secondary data analysis-NIA.md</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Secondary data analysis.md</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Survey and Interview Example.md</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Survey and interview data-NIA.md</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Survey, interview, and biological data (tiered...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Technology development.md</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Generated_File SBERT ROUGE\n",
       "0                   Analysis of social media posts.md  0.80  0.40\n",
       "1   Basic Research from a Non-Human Source Example.md  0.81  0.46\n",
       "2   Clinical Data from Human Research Participants.md  0.71  0.24\n",
       "3   Clinical and MRI data from human research part...  0.73  0.28\n",
       "4               Clinical data (human biospecimens).md  0.81  0.38\n",
       "5   Clinical data from human research participants...  0.77  0.35\n",
       "6   Drug discovery including intellectual property.md  0.81  0.33\n",
       "7   Gene expression analysis data from non-human m...  0.80  0.37\n",
       "8             Genomic data from a non-human source.md  0.74  0.33\n",
       "9    Genomic data from human research participants.md  0.74  0.30\n",
       "10    HeLa Cell Whole Genome Sequence (DNA or RNA).md  0.83  0.45\n",
       "11                       Human Clinical Trial Data.md  0.73  0.31\n",
       "12             Human clinical and genomic data-NIA.md  0.84  0.38\n",
       "13                Human clinical and genomics data.md  0.72  0.44\n",
       "14                              Human genomic data.md  0.66  0.37\n",
       "15                               Human survey data.md  0.79  0.42\n",
       "16                       Non-human data (primates).md  0.75  0.31\n",
       "17                    Non-human data (rodents)-NIA.md  0.81  0.47\n",
       "18                 Secondary Data Analysis Example.md  0.80  0.41\n",
       "19  Secondary Data Analysis on Data from Human Sub...  0.81  0.36\n",
       "20                     Secondary data analysis-NIA.md  0.76  0.31\n",
       "21                         Secondary data analysis.md  0.65  0.23\n",
       "22                    Survey and Interview Example.md  0.76  0.36\n",
       "23                   Survey and interview data-NIA.md  0.78  0.35\n",
       "24  Survey, interview, and biological data (tiered...  0.79  0.31\n",
       "25                          Technology development.md  0.66  0.43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Element-level summary table (Mean ¬± SD):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Element</th>\n",
       "      <th>SBERT</th>\n",
       "      <th>ROUGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>element_1a</td>\n",
       "      <td>0.88 ¬± 0.07</td>\n",
       "      <td>0.55 ¬± 0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>element_1b</td>\n",
       "      <td>0.76 ¬± 0.11</td>\n",
       "      <td>0.45 ¬± 0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>element_1c</td>\n",
       "      <td>0.81 ¬± 0.08</td>\n",
       "      <td>0.50 ¬± 0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>element_2</td>\n",
       "      <td>0.81 ¬± 0.14</td>\n",
       "      <td>0.49 ¬± 0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>element_3</td>\n",
       "      <td>0.80 ¬± 0.11</td>\n",
       "      <td>0.44 ¬± 0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>element_4a</td>\n",
       "      <td>0.80 ¬± 0.08</td>\n",
       "      <td>0.52 ¬± 0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>element_4b</td>\n",
       "      <td>0.88 ¬± 0.10</td>\n",
       "      <td>0.57 ¬± 0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>element_4c</td>\n",
       "      <td>0.89 ¬± 0.07</td>\n",
       "      <td>0.56 ¬± 0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>element_5a</td>\n",
       "      <td>0.84 ¬± 0.12</td>\n",
       "      <td>0.61 ¬± 0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>element_5b</td>\n",
       "      <td>0.82 ¬± 0.09</td>\n",
       "      <td>0.51 ¬± 0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>element_5c</td>\n",
       "      <td>0.86 ¬± 0.09</td>\n",
       "      <td>0.55 ¬± 0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>element_6</td>\n",
       "      <td>0.87 ¬± 0.07</td>\n",
       "      <td>0.57 ¬± 0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Element        SBERT        ROUGE\n",
       "0   element_1a  0.88 ¬± 0.07  0.55 ¬± 0.18\n",
       "1   element_1b  0.76 ¬± 0.11  0.45 ¬± 0.20\n",
       "2   element_1c  0.81 ¬± 0.08  0.50 ¬± 0.26\n",
       "3    element_2  0.81 ¬± 0.14  0.49 ¬± 0.20\n",
       "4    element_3  0.80 ¬± 0.11  0.44 ¬± 0.22\n",
       "5   element_4a  0.80 ¬± 0.08  0.52 ¬± 0.24\n",
       "6   element_4b  0.88 ¬± 0.10  0.57 ¬± 0.26\n",
       "7   element_4c  0.89 ¬± 0.07  0.56 ¬± 0.23\n",
       "8   element_5a  0.84 ¬± 0.12  0.61 ¬± 0.25\n",
       "9   element_5b  0.82 ¬± 0.09  0.51 ¬± 0.20\n",
       "10  element_5c  0.86 ¬± 0.09  0.55 ¬± 0.25\n",
       "11   element_6  0.87 ¬± 0.07  0.57 ¬± 0.21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saved formatted tables ‚Üí\n",
      "‚Ä¢ C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\evaluation_results\\summary_full_table_mean_only.csv\n",
      "‚Ä¢ C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\\data\\outputs\\evaluation_results\\summary_element_table_mean_sd.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üßÆ Step 8: Summarize Evaluation Results (with Generated_File titles)\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Auto-detect project root ---\n",
    "# --------------------------------------------------------\n",
    "# üóÇÔ∏è Define ROOT_DIR manually to your project folder\n",
    "# --------------------------------------------------------\n",
    "ROOT_DIR = Path(r\"C:\\Users\\Nahid\\AI_DMP\\DMP_RAG_Pipeline\")  # ‚úÖ change if needed\n",
    "\n",
    "EVAL_DIR = ROOT_DIR / \"data\" / \"outputs\" / \"evaluation_results\"\n",
    "\n",
    "# --- Load CSVs ---\n",
    "full_path = EVAL_DIR / \"full_dmp_pdf_comparison_fuzzy.csv\"\n",
    "elem_path = EVAL_DIR / \"element_similarity_exact_titles.csv\"\n",
    "\n",
    "df_full = pd.read_csv(full_path)\n",
    "df_elem = pd.read_csv(elem_path)\n",
    "\n",
    "print(f\"‚úÖ Loaded full-document ({len(df_full)} rows)\")\n",
    "print(f\"‚úÖ Loaded element-level ({len(df_elem)} rows)\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# üß© 1Ô∏è‚É£ FULL-DOCUMENT LEVEL SUMMARY (Mean Only, by Generated_File)\n",
    "# ============================================================\n",
    "\n",
    "# Prefer \"Generated_File\" column; fallback to detected one\n",
    "if \"Generated_File\" in df_full.columns:\n",
    "    project_col = \"Generated_File\"\n",
    "else:\n",
    "    project_col = next(\n",
    "        (c for c in df_full.columns if \"title\" in c.lower() or \"project\" in c.lower() or \"matched\" in c.lower()),\n",
    "        df_full.columns[0],\n",
    "    )\n",
    "\n",
    "# Find numeric columns\n",
    "numeric_cols = [c for c in df_full.columns if \"sbert\" in c.lower() or \"rouge\" in c.lower()]\n",
    "\n",
    "# Compute mean per file (if multiple rows)\n",
    "df_full_summary = (\n",
    "    df_full.groupby(project_col)[numeric_cols]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Format to 2 decimals\n",
    "df_full_summary[\"SBERT\"] = df_full_summary[numeric_cols[0]].apply(lambda x: f\"{x:.2f}\")\n",
    "df_full_summary[\"ROUGE\"] = df_full_summary[numeric_cols[1]].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "# Reorder columns and rename for clarity\n",
    "df_full_table = df_full_summary[[project_col, \"SBERT\", \"ROUGE\"]].rename(\n",
    "    columns={project_col: \"Generated_File\"}\n",
    ")\n",
    "\n",
    "print(\"üìä Full-document summary table (Mean only, by Generated_File):\")\n",
    "display(df_full_table)\n",
    "\n",
    "# ============================================================\n",
    "# üß© 2Ô∏è‚É£ ELEMENT-LEVEL SUMMARY (Mean ¬± SD)\n",
    "# ============================================================\n",
    "\n",
    "elem_col = next(\n",
    "    (c for c in df_elem.columns if \"element\" in c.lower()),\n",
    "    df_elem.columns[0],\n",
    ")\n",
    "\n",
    "numeric_cols_elem = [c for c in df_elem.columns if \"sbert\" in c.lower() or \"rouge\" in c.lower()]\n",
    "df_elem_summary = (\n",
    "    df_elem.groupby(elem_col)[numeric_cols_elem]\n",
    "    .agg([\"mean\", \"std\"])\n",
    "    .reset_index()\n",
    ")\n",
    "flat_cols_elem = [elem_col, \"SBERT_Mean\", \"SBERT_SD\", \"ROUGE_Mean\", \"ROUGE_SD\"]\n",
    "df_elem_summary.columns = flat_cols_elem\n",
    "\n",
    "df_elem_summary[\"SBERT\"] = df_elem_summary.apply(\n",
    "    lambda r: f\"{r['SBERT_Mean']:.2f} ¬± {r['SBERT_SD']:.2f}\", axis=1)\n",
    "df_elem_summary[\"ROUGE\"] = df_elem_summary.apply(\n",
    "    lambda r: f\"{r['ROUGE_Mean']:.2f} ¬± {r['ROUGE_SD']:.2f}\", axis=1)\n",
    "\n",
    "df_elem_table = df_elem_summary[[elem_col, \"SBERT\", \"ROUGE\"]].rename(\n",
    "    columns={elem_col: \"Element\"}\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Element-level summary table (Mean ¬± SD):\")\n",
    "display(df_elem_table)\n",
    "\n",
    "# ============================================================\n",
    "# üíæ Save formatted tables\n",
    "# ============================================================\n",
    "out_full = EVAL_DIR / \"summary_full_table_mean_only.csv\"\n",
    "out_elem = EVAL_DIR / \"summary_element_table_mean_sd.csv\"\n",
    "\n",
    "df_full_table.to_csv(out_full, index=False)\n",
    "df_elem_table.to_csv(out_elem, index=False)\n",
    "\n",
    "print(f\"\\nüíæ Saved formatted tables ‚Üí\\n‚Ä¢ {out_full}\\n‚Ä¢ {out_elem}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ven3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
